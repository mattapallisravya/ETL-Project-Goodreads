{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from pandas import to_datetime\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# SQLAlchemy\n",
    "from sqlalchemy import create_engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file and put it into a dataframe\n",
    "csv_file = 'Resources/original_book_data.csv'\n",
    "book_df = pd.read_csv(csv_file, na_filter = True, na_values = '[]')\n",
    "book_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling NA values with other values to avoid data loss.\n",
    "book_df['price'] = book_df['price'].fillna(0)\n",
    "book_df['awards'] = book_df['awards'].fillna(\"['not awarded']\")\n",
    "book_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the columns we want in a new DF\n",
    "book_df2 = book_df[['title', 'author','rating', 'description', 'language', 'isbn',\n",
    "    'genres', 'pages', 'publishDate', 'publisher', 'numRatings', 'likedPercent','awards','price']].copy()\n",
    "\n",
    "# Filter DF to only include books in English and drop null values\n",
    "book_df2 = book_df2[book_df2['language'] == 'English']\n",
    "book_df2.dropna(inplace = True)\n",
    "book_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the column dtypes\n",
    "book_df2.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert the Title, Author, Language column to a string\n",
    "book_df2['title'] = book_df2['title'].astype('string')\n",
    "book_df2['author'] = book_df2['author'].astype('string')\n",
    "book_df2['language'] = book_df2['language'].astype('string')\n",
    "book_df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert the ISBN column to a string\n",
    "book_df2['isbn'] = book_df2['isbn'].astype('string')\n",
    "\n",
    "# drop books with the ISBN of 9999999999999\n",
    "book_df2.drop(book_df2[book_df2['isbn'] == '9999999999999'].index, inplace = True)\n",
    "\n",
    "# remove duplicate ISBN numbers\n",
    "book_df2.drop_duplicates(subset=['isbn'], keep = 'first', inplace = True)\n",
    "\n",
    "book_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = book_df2[['author', 'isbn']].copy()\n",
    "test_df = test_df.set_index('isbn')\n",
    "test_df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Author Strings by a comma\n",
    "\n",
    "new_df = pd.DataFrame(test_df['author'].str.split(pat=',', n=-1, expand=True))\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the index and column of the first author\n",
    "author_table = new_df.loc[:, :0]\n",
    "\n",
    "#name the author column \n",
    "author_table.columns = ['author']\n",
    "\n",
    "author_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the authors name\n",
    "split_author = pd.DataFrame(author_table['author'].str.split(pat='(', n=-1, expand=True))\n",
    "split_author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the index and column of the first author\n",
    "author_df = split_author.loc[:, :0]\n",
    "\n",
    "#name the author column \n",
    "author_df.columns = ['main author']\n",
    "\n",
    "#rename the index\n",
    "author_df = author_df.rename(index = {'' : 'isbn'})\n",
    "\n",
    "author_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv to share with the team\n",
    "author_df.to_csv('author_table.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge data from the author table to the main data\n",
    "main_book_data = pd.merge(book_df2, author_df, on = 'isbn')\n",
    "\n",
    "#remove the original author column\n",
    "main_book_data = main_book_data.drop(columns=['author'])\n",
    "\n",
    "main_book_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering dates that doesn't follow correct format\n",
    "data_df1 = main_book_data.loc[main_book_data[\"publishDate\"].str.len()>8]\n",
    "#data_df1.drop(columns=\"Unnamed: 0\")\n",
    "data_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned the published date column to bring all dates to one format\n",
    "data_df1[\"publishedDate\"]= pd.to_datetime(data_df1['publishDate'],errors = 'coerce')\n",
    "\n",
    "# Drop all NA values \n",
    "data_df1=data_df1.dropna()\n",
    "data_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates new column with year published\n",
    "data_df1['yearPublished'] = pd.DatetimeIndex(data_df1['publishedDate']).year\n",
    "data_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering the data for latest 5 yrs\n",
    "data_df1=data_df1[(data_df1['yearPublished']>=2015)&(data_df1['yearPublished']<=2020)].reset_index(inplace=False)\n",
    "data_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting dataframe to csv\n",
    "data_df1.to_csv('filtered_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a copy of dataframe\n",
    "awards_df = data_df1.copy()\n",
    "awards_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep only the ISBN and awards Column\n",
    "awards_df1 = awards_df[['isbn', 'awards']].copy()\n",
    "\n",
    "awards_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminate the [ ' ] marks in the awards column\n",
    "awards_df1['awards'] = awards_df1['awards'].str.replace('[', '')\n",
    "awards_df1['awards'] = awards_df1['awards'].str.replace(']', '')\n",
    "awards_df1['awards'] = awards_df1['awards'].str.replace(\"'\", \"\")\n",
    "awards_df1['awards'] = awards_df1['awards'].str.replace('\"', \"\")\n",
    "awards_df1['awards'] = awards_df1['awards'].str.replace('()', \"\")\n",
    "awards_df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new df and flatten the awards into a new list\n",
    "new_df_awards = awards_df1['awards'].copy()\n",
    "\n",
    "genre_values = np.core.defchararray.split(new_df_awards.values.astype('str'),', ')\n",
    "flatten_list_awards = [item for sublist in genre_values for item in sublist]\n",
    "len(flatten_list_awards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take the award list and add unique values to the unique_award_list\n",
    "unique_award_list = []\n",
    "for x in flatten_list_awards:\n",
    "    if x not in unique_award_list:\n",
    "        unique_award_list.append(x)\n",
    "\n",
    "len(unique_award_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a table of the unique award values\n",
    "award_tables = pd.DataFrame(unique_award_list, columns = ['award'])\n",
    "\n",
    "# Remove year in brackets\n",
    "award_tables=award_tables['award'].str.split(pat='(', n=1,expand=True)\n",
    "award_tables = award_tables.rename(columns={0:\"award\"})\n",
    "award_unique = award_tables[\"award\"].unique()\n",
    "\n",
    "#create a table of the unique award values after removing year which in brackets\n",
    "award_tables1 = pd.DataFrame(award_unique, columns = ['award'])\n",
    "award_tables1\n",
    "\n",
    "# Add a Primary Key to each award\n",
    "award_tables1['award_id'] = award_tables1.index + 600\n",
    "award_tables1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of ISBN and awards that will be zipped into a df\n",
    "last_isbn_list = []\n",
    "last_award_list = []\n",
    "\n",
    "for index, row in awards_df1.iterrows():\n",
    "    row['awards'].split(',')\n",
    "    row['awards'].split(' ')\n",
    "    isbn = row['isbn']\n",
    "    for x in row['awards'].split(','):\n",
    "        last_isbn_list.append(isbn)\n",
    "        last_award_list.append(x)\n",
    "\n",
    "#Check the length of each\n",
    "\n",
    "print(len(last_isbn_list))\n",
    "print(len(last_award_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip the isbn and awards into a df\n",
    "book_award_table = pd.DataFrame(zip(last_isbn_list, last_award_list), columns = ['isbn', 'award'])\n",
    "\n",
    "# strip leading and trailing white space in the awards column\n",
    "book_award_table['award'] = book_award_table['award'].str.strip()\n",
    "\n",
    "# Remove year in brackets\n",
    "book_award_table['award']= book_award_table['award'].str.split(pat='(', n=1,expand=True)\n",
    "\n",
    "book_award_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **This dataframe has to be loaded to database**\n",
    "# merging the dataframes\n",
    "merge_award_df = pd.merge(award_tables1,book_award_table,on=\"award\")\n",
    "merge_award_df = merge_award_df.drop(columns=\"award\")\n",
    "merge_award_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep only the ISBN and Genre Column\n",
    "genre_df = data_df1[['isbn', 'genres']].copy()\n",
    "\n",
    "genre_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminate the [ ' ] marks in the genres column\n",
    "\n",
    "genre_df2 = genre_df.copy()\n",
    "genre_df2['genres'] = genre_df2['genres'].str.replace('[', '')\n",
    "genre_df2['genres'] = genre_df2['genres'].str.replace(']', '')\n",
    "genre_df2['genres'] = genre_df2['genres'].str.replace(\"'\", \"\")\n",
    "genre_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new df and flatten the genres into a new list\n",
    "new_df = genre_df2['genres'].copy()\n",
    "genre_values = np.core.defchararray.split(new_df.values.astype('str'),', ')\n",
    "flatten_list = [item for sublist in genre_values for item in sublist]\n",
    "flatten_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take the genres list and add unique values to the unique_genre_list\n",
    "unique_genre_list = []\n",
    "for x in flatten_list:\n",
    "    if x not in unique_genre_list:\n",
    "        unique_genre_list.append(x)\n",
    "\n",
    "unique_genre_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the lengths of the two lists to make sure it worked \n",
    "print(len(flatten_list))\n",
    "print(len(unique_genre_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **This dataframe has to be loaded to database**\n",
    "#create a table of the unique genre values\n",
    "genre_tables = pd.DataFrame(unique_genre_list, columns = ['genre'])\n",
    "\n",
    "# Add a Primary Key to each genre\n",
    "genre_tables['genre_id'] = genre_tables.index + 500\n",
    "genre_tables = genre_tables.loc[:,['genre_id','genre']]\n",
    "genre_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of ISBN and Genres that will be zipped into a df\n",
    "last_isbn_list = []\n",
    "last_genre_list = []\n",
    "\n",
    "for index, row in genre_df2.iterrows():\n",
    "    row['genres'].split(',')\n",
    "    row['genres'].split(' ')\n",
    "    isbn = row['isbn']\n",
    "    for x in row['genres'].split(','):\n",
    "        last_isbn_list.append(isbn)\n",
    "        last_genre_list.append(x)\n",
    "\n",
    "#Check the length of each\n",
    "\n",
    "print(len(last_isbn_list))\n",
    "print(len(last_genre_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip the isbn and genres into a df\n",
    "book_genre_table = pd.DataFrame(zip(last_isbn_list, last_genre_list), columns = ['isbn', 'genre'])\n",
    "\n",
    "# strip leading and trailing white space in the genre column\n",
    "book_genre_table['genre'] = book_genre_table['genre'].str.strip()\n",
    "\n",
    "book_genre_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#**This dataframe has to be loaded to database**\n",
    "merge_genre_df = pd.merge(genre_tables,book_genre_table,on=\"genre\")\n",
    "merge_genre_df.drop(columns=\"genre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** Should be loaded to database **\n",
    "final_book_df = data_df1.drop(columns=[\"index\",\"genres\",\"publishDate\",\"awards\"])\n",
    "final_book_df = final_book_df.loc[:,['isbn','title','language','main author','description','pages','publisher','publishedDate','yearPublished','rating','numRatings','likedPercent','price']]\n",
    "final_book_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_book_df.to_csv('cleaned_tables/final_book.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to local database\n",
    "\n",
    "protocol = 'postgresql'\n",
    "username = 'postgres'\n",
    "password = 'postgres'\n",
    "host = 'localhost'\n",
    "port = 5432\n",
    "database_name = 'Book_db'\n",
    "connection_string = f'{protocol}://{username}:{password}@{host}:{port}/{database_name}'\n",
    "engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preview table names\n",
    "\n",
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use pandas to load DataFrame into database\n",
    "\n",
    "# ** do we have to convert all DFs to a csv and/or json file like they did in the example?\n",
    "\n",
    "# WORKS MIGHT NEED TO REMOVE DUP \n",
    "final_book_df.to_sql('book', con=engine, if_exists='append', index=False)\n",
    "award_tables1.to_sql('awards', con=engine, if_exists='append', index=False)\n",
    "merge_award_df.to_sql('award_isbn', con=engine, if_exists='append', index=False)\n",
    "genre_tables.to_sql('genres', con=engine, if_exists='append', index=False)\n",
    "merge_genre_df.to_sql('genre_isbn', con=engine, if_exists='append', index=False)\n",
    "\n",
    "\n",
    "\n",
    "# #** missing tables **\n",
    "# # author_info_df.to_sql('author', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query('select * from book', con=engine).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query('select * from awards', con=engine).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query('select * from genres', con=engine).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query('select * from genre_isbn', con=engine).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonDataOne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ffeadad9e6503ab0a318729a49619af2b1f0e62908a55aa7b893bc580c5c8ce1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
